{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPb9mg4OudzHjIHDOZXZZBi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seadreamjj/danmu-ID/blob/main/%E7%8C%AB%E8%80%B3%E6%BC%AB%E6%92%AD%E5%BC%B9%E5%B9%95id%E8%AF%BB%E5%8F%96%EF%BC%88%E7%9B%B4%E6%8E%A5%E5%87%BA%E8%A1%A8%E7%89%88%EF%BC%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "直接读取表格循环（猫耳）"
      ],
      "metadata": {
        "id": "w4rlEUQ_uVK-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmvPQkwroxX9",
        "outputId": "726346be-0b61-4595-9603-9f66008fa000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "处理 URL 76557 时发生错误: name 'drama_id' is not defined\n",
            "处理 URL 77771 时发生错误: name 'drama_id' is not defined\n",
            "处理 URL 68664 时发生错误: name 'drama_id' is not defined\n",
            "处理 URL 76879 时发生错误: name 'drama_id' is not defined\n",
            "处理 URL 75856 时发生错误: name 'drama_id' is not defined\n",
            "处理 URL 77888 时发生错误: name 'drama_id' is not defined\n",
            "处理 URL 77223 时发生错误: name 'drama_id' is not defined\n",
            "处理 URL 77249 时发生错误: name 'drama_id' is not defined\n",
            "处理 URL 77591 时发生错误: name 'drama_id' is not defined\n",
            "处理 URL 77685 时发生错误: name 'drama_id' is not defined\n",
            "处理 URL 77035 时发生错误: name 'drama_id' is not defined\n",
            "处理 URL 75085 时发生错误: name 'drama_id' is not defined\n",
            "处理 URL 77918 时发生错误: name 'drama_id' is not defined\n",
            "处理 URL 77937 时发生错误: name 'drama_id' is not defined\n",
            "处理完成，结果已保存到处理后的 Excel 文件中。\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# 读取上传的 Excel 文件\n",
        "file_path = '/content/猫耳在播剧id（跑程序版）.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# 假设表格中有一列名为 'URL'，包含剧集链接\n",
        "urls = df['url']\n",
        "\n",
        "# 创建新的列来保存 uid 结果和剧名\n",
        "df['uid_result'] = None\n",
        "df['drama_name'] = None\n",
        "\n",
        "# 定义基础的 API URL\n",
        "drama_url_base = 'http://www.missevan.com/dramaapi/getdrama?drama_id='\n",
        "sound_url_base = 'http://www.missevan.com/sound/getdm?soundid='\n",
        "\n",
        "# 遍历每个 URL\n",
        "for index, drama_url in enumerate(urls):\n",
        "    try:\n",
        "        # 提取剧集的 ID（取URL最后的数字部分）\n",
        "        drama_id = drama_url.split(\"/\")[-1]\n",
        "\n",
        "        # 构建完整的 API 请求 URL\n",
        "        url = drama_url_base + drama_id\n",
        "\n",
        "        # 请求剧集数据\n",
        "        drama_result = requests.get(url).text\n",
        "\n",
        "        # 提取剧名（假设剧名在 JSON 的 \"name\" 字段中）\n",
        "        name_pattern = re.compile(r'\"name\":\"(.*?)\"')  # 正则表达式提取剧名\n",
        "        drama_name = re.findall(name_pattern, drama_result)\n",
        "        if drama_name:\n",
        "            drama_name = drama_name[0]\n",
        "        else:\n",
        "            drama_name = \"Unknown\"\n",
        "\n",
        "        # 使用正则表达式提取 sound_id 和 pay_type\n",
        "        pattern1 = re.compile(r'\"sound_id\":(\\d+),')  # 提取 sound_id\n",
        "        pattern2 = re.compile(r'\"need_pay\":(\\d+),')  # 提取付费状态 need_pay\n",
        "        sound_id = re.findall(pattern1, drama_result)\n",
        "        pay_type = re.findall(pattern2, drama_result)\n",
        "\n",
        "        # 去掉第一个非付费项\n",
        "        pay_type = pay_type[1:]\n",
        "\n",
        "        # 创建 DataFrame 保存提取的数据\n",
        "        drama = pd.DataFrame({'sound_id': sound_id, 'pay_type': pay_type})\n",
        "\n",
        "        # 筛选付费 sound_id\n",
        "        sound_id_filtered = list(drama['sound_id'][drama['pay_type'] == '1'])\n",
        "\n",
        "        # 获取每个 sound_id 对应的 uid\n",
        "        uids = []\n",
        "        for sid in sound_id_filtered:\n",
        "            sound_url = sound_url_base + sid\n",
        "            sound_result = requests.get(sound_url).text\n",
        "\n",
        "            # 提取 uid（假设通过 p=\"...\" 来抓取弹幕信息）\n",
        "            pattern3 = re.compile(r'p=\"(.+?)\"')\n",
        "            dm = re.findall(pattern3, sound_result)\n",
        "\n",
        "            # 分割并提取 uid\n",
        "            dm_temp = pd.DataFrame({'dm': dm})\n",
        "            dms_split = dm_temp['dm'].str.split('>', expand=True)[0]\n",
        "            uid = dms_split.str.split(',', expand=True)[6]\n",
        "\n",
        "            # 去重处理\n",
        "            unique_uids = uid.unique().tolist()\n",
        "            uids.extend(unique_uids)\n",
        "\n",
        "        # 保存结果到表格中\n",
        "        df.at[index, 'uid_result'] = ','.join(uids)\n",
        "        df.at[index, 'drama_name'] = drama_name\n",
        "\n",
        "        # 打印剧名和 uid 结果\n",
        "        print(f\"剧名: {drama_name}, UIDs: {uids}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # 如果发生错误，记录错误信息\n",
        "        df.at[index, 'uid_result'] = f\"Error: {e}\"\n",
        "        df.at[index, 'drama_name'] = \"Unknown\"\n",
        "        print(f\"处理 URL {drama_url} 时发生错误: {e}\")\n",
        "\n",
        "# 保存结果回到 Excel 文件中\n",
        "output_path = '/content/猫耳在播剧id（跑程序版）.xlsx'\n",
        "df.to_excel(output_path, index=False)\n",
        "\n",
        "print(\"处理完成，结果已保存到处理后的 Excel 文件中。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "检查api获取是否正确"
      ],
      "metadata": {
        "id": "xoNL7g3uuZzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 读取上传的 Excel 文件\n",
        "file_path = '/content/猫耳在播剧id（跑程序版）.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# 假设表格中有一列名为 'URL'，包含剧集链接\n",
        "urls = df['url']\n",
        "\n",
        "# 定义基础的 API URL\n",
        "drama_url_base = 'http://www.missevan.com/dramaapi/getdrama?drama_id='\n",
        "\n",
        "# 遍历前几个 URL，输出 drama_id 和 API URL\n",
        "for index, drama_url in enumerate(urls[:5]):  # 只检查前 5 个 URL\n",
        "    try:\n",
        "        # 确保 drama_url 是字符串类型\n",
        "        if not isinstance(drama_url, str):\n",
        "            drama_url = str(drama_url)\n",
        "\n",
        "        # 提取剧集的 ID（取URL最后的数字部分）\n",
        "        drama_id = drama_url.split(\"/\")[-1]\n",
        "\n",
        "        # 构建完整的 API 请求 URL\n",
        "        api_url = drama_url_base + drama_id\n",
        "\n",
        "        # 打印 drama_id 和 API 请求 URL\n",
        "        print(f\"剧集 ID: {drama_id}\")\n",
        "        print(f\"API 请求 URL: {api_url}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"处理 URL {drama_url} 时发生错误: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWzV4h2Judfc",
        "outputId": "59d2f4c4-4e44-4b1e-bf7b-17dd57ada14c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "剧集 ID: 76557\n",
            "API 请求 URL: http://www.missevan.com/dramaapi/getdrama?drama_id=76557\n",
            "--------------------------------------------------\n",
            "剧集 ID: 77771\n",
            "API 请求 URL: http://www.missevan.com/dramaapi/getdrama?drama_id=77771\n",
            "--------------------------------------------------\n",
            "剧集 ID: 68664\n",
            "API 请求 URL: http://www.missevan.com/dramaapi/getdrama?drama_id=68664\n",
            "--------------------------------------------------\n",
            "剧集 ID: 76879\n",
            "API 请求 URL: http://www.missevan.com/dramaapi/getdrama?drama_id=76879\n",
            "--------------------------------------------------\n",
            "剧集 ID: 75856\n",
            "API 请求 URL: http://www.missevan.com/dramaapi/getdrama?drama_id=75856\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "api没有错误，试试直接输出"
      ],
      "metadata": {
        "id": "YgzQUYWrvcys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# 读取上传的 Excel 文件\n",
        "file_path = '/content/猫耳在播剧id（跑程序版）.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# 假设表格中有 '剧名' 和 'URL' 两列，分别包含剧集名称和剧集链接\n",
        "titles = df['剧名']\n",
        "urls = df['url']\n",
        "\n",
        "# 定义基础的 API URL\n",
        "drama_url_base = 'http://www.missevan.com/dramaapi/getdrama?drama_id='\n",
        "\n",
        "# 用于存储最终的结果\n",
        "final_results = []\n",
        "\n",
        "# 遍历每个剧集的名称和 URL\n",
        "for title, drama_url in zip(titles, urls):\n",
        "    try:\n",
        "        # 确保 drama_url 是字符串类型\n",
        "        if not isinstance(drama_url, str):\n",
        "            drama_url = str(drama_url)\n",
        "\n",
        "        # 提取剧集的 ID（取URL最后的数字部分）\n",
        "        drama_id = drama_url.split(\"/\")[-1]\n",
        "\n",
        "        # 构建完整的 API 请求 URL\n",
        "        api_url = drama_url_base + drama_id\n",
        "\n",
        "        # 请求 API 获取剧集数据\n",
        "        drama_result = requests.get(api_url).text\n",
        "\n",
        "        # 提取 sound_id 和付费状态\n",
        "        pattern1 = re.compile(r'\"sound_id\":(\\d+),')  # 提取 sound_id\n",
        "        pattern2 = re.compile(r'\"need_pay\":(\\d+),')  # 提取付费状态 need_pay\n",
        "        sound_id = re.findall(pattern1, drama_result)\n",
        "        pay_type = re.findall(pattern2, drama_result)\n",
        "\n",
        "        # 去掉第一个非付费项\n",
        "        pay_type = pay_type[1:]\n",
        "\n",
        "        # 创建 DataFrame 并筛选付费 sound_id\n",
        "        drama = pd.DataFrame({'sound_id': sound_id, 'pay_type': pay_type})\n",
        "        paid_sound_ids = list(drama['sound_id'][drama['pay_type'] == '1'])\n",
        "\n",
        "        # 存储弹幕 UID 的 DataFrame\n",
        "        dm1 = pd.DataFrame()\n",
        "\n",
        "        # 循环处理每个付费 sound_id，获取弹幕信息\n",
        "        for sid in paid_sound_ids:\n",
        "            sound_url = f'http://www.missevan.com/sound/getdm?soundid={sid}'\n",
        "            sound_result = requests.get(sound_url).text\n",
        "\n",
        "            # 提取弹幕内容\n",
        "            pattern3 = re.compile(r'p=\"(.+?)\"')\n",
        "            dm = re.findall(pattern3, sound_result)\n",
        "\n",
        "            # 将弹幕数据存储到 DataFrame\n",
        "            dm_temp = pd.DataFrame({'dm': dm})\n",
        "            dms_split = dm_temp['dm'].str.split('>', expand=True)[0]\n",
        "            uid = dms_split.str.split(',', expand=True)[6]\n",
        "            dm_temp['uid'] = uid\n",
        "\n",
        "            # 合并 UID 数据\n",
        "            if dm1.empty:\n",
        "                dm1 = dm_temp\n",
        "            else:\n",
        "                dm1 = pd.concat([dm1, dm_temp], ignore_index=True)\n",
        "\n",
        "        # 输出剧名和不重复的 UID 数量\n",
        "        unique_uids = len(dm1['uid'].unique())\n",
        "        print(f\"剧名: {title}, 不重复的UID数量: {unique_uids}\")\n",
        "\n",
        "        # 存储结果\n",
        "        final_results.append({'剧名': title, 'UID数量': unique_uids})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"处理剧名 {title} 时发生错误: {e}\")\n",
        "\n",
        "# 将结果转为 DataFrame 并导出\n",
        "results_df = pd.DataFrame(final_results)\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U34oVywFvg0V",
        "outputId": "522487ef-6f04-43a5-e72d-a77728c49f3c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "剧名: 惊封2下, 不重复的UID数量: 9777\n",
            "剧名: 提灯看刺刀（上）, 不重复的UID数量: 5758\n",
            "剧名: 台风眼2, 不重复的UID数量: 5540\n",
            "剧名: 吞海3下, 不重复的UID数量: 4323\n",
            "剧名: 梦魇直播间1, 不重复的UID数量: 3451\n",
            "剧名: 三嫁2, 不重复的UID数量: 1986\n",
            "剧名: 跨界2, 不重复的UID数量: 1776\n",
            "剧名: 暗癖, 不重复的UID数量: 1641\n",
            "剧名: 偷风不偷月（下）, 不重复的UID数量: 1200\n",
            "剧名: 千杯, 不重复的UID数量: 829\n",
            "剧名: 于青, 不重复的UID数量: 743\n",
            "剧名: 月下安途, 不重复的UID数量: 668\n",
            "剧名: 三伏2, 不重复的UID数量: 591\n",
            "剧名: 烟花过境（BG）, 不重复的UID数量: 116\n",
            "          剧名  UID数量\n",
            "0       惊封2下   9777\n",
            "1   提灯看刺刀（上）   5758\n",
            "2       台风眼2   5540\n",
            "3       吞海3下   4323\n",
            "4     梦魇直播间1   3451\n",
            "5        三嫁2   1986\n",
            "6        跨界2   1776\n",
            "7         暗癖   1641\n",
            "8   偷风不偷月（下）   1200\n",
            "9         千杯    829\n",
            "10        于青    743\n",
            "11      月下安途    668\n",
            "12       三伏2    591\n",
            "13  烟花过境（BG）    116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "进一步做输出表格版\n"
      ],
      "metadata": {
        "id": "SJU7g5KVw2vO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# 读取上传的 Excel 文件\n",
        "file_path = '/content/猫耳在播剧id（跑程序版）.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# 假设表格中有 '剧名' 和 'URL' 两列，分别包含剧集名称和剧集链接\n",
        "titles = df['剧名']\n",
        "urls = df['url']\n",
        "\n",
        "# 定义基础的 API URL\n",
        "drama_url_base = 'http://www.missevan.com/dramaapi/getdrama?drama_id='\n",
        "\n",
        "# 用于存储最终的结果\n",
        "final_results = []\n",
        "\n",
        "# 为 DataFrame 添加一列 'id2'，初始为 None\n",
        "df['id2'] = None\n",
        "\n",
        "# 遍历每个剧集的名称和 URL\n",
        "for idx, (title, drama_url) in enumerate(zip(titles, urls)):\n",
        "    try:\n",
        "        # 确保 drama_url 是字符串类型\n",
        "        if not isinstance(drama_url, str):\n",
        "            drama_url = str(drama_url)\n",
        "\n",
        "        # 提取剧集的 ID（取URL最后的数字部分）\n",
        "        drama_id = drama_url.split(\"/\")[-1]\n",
        "\n",
        "        # 构建完整的 API 请求 URL\n",
        "        api_url = drama_url_base + drama_id\n",
        "\n",
        "        # 请求 API 获取剧集数据\n",
        "        drama_result = requests.get(api_url).text\n",
        "\n",
        "        # 提取 sound_id 和付费状态\n",
        "        pattern1 = re.compile(r'\"sound_id\":(\\d+),')  # 提取 sound_id\n",
        "        pattern2 = re.compile(r'\"need_pay\":(\\d+),')  # 提取付费状态 need_pay\n",
        "        sound_id = re.findall(pattern1, drama_result)\n",
        "        pay_type = re.findall(pattern2, drama_result)\n",
        "\n",
        "        # 去掉第一个非付费项\n",
        "        pay_type = pay_type[1:]\n",
        "\n",
        "        # 创建 DataFrame 并筛选付费 sound_id\n",
        "        drama = pd.DataFrame({'sound_id': sound_id, 'pay_type': pay_type})\n",
        "        paid_sound_ids = list(drama['sound_id'][drama['pay_type'] == '1'])\n",
        "\n",
        "        # 存储弹幕 UID 的 DataFrame\n",
        "        dm1 = pd.DataFrame()\n",
        "\n",
        "        # 循环处理每个付费 sound_id，获取弹幕信息\n",
        "        for sid in paid_sound_ids:\n",
        "            sound_url = f'http://www.missevan.com/sound/getdm?soundid={sid}'\n",
        "            sound_result = requests.get(sound_url).text\n",
        "\n",
        "            # 提取弹幕内容\n",
        "            pattern3 = re.compile(r'p=\"(.+?)\"')\n",
        "            dm = re.findall(pattern3, sound_result)\n",
        "\n",
        "            # 将弹幕数据存储到 DataFrame\n",
        "            dm_temp = pd.DataFrame({'dm': dm})\n",
        "            dms_split = dm_temp['dm'].str.split('>', expand=True)[0]\n",
        "            uid = dms_split.str.split(',', expand=True)[6]\n",
        "            dm_temp['uid'] = uid\n",
        "\n",
        "            # 合并 UID 数据\n",
        "            if dm1.empty:\n",
        "                dm1 = dm_temp\n",
        "            else:\n",
        "                dm1 = pd.concat([dm1, dm_temp], ignore_index=True)\n",
        "\n",
        "        # 获取不重复的 UID 数量\n",
        "        unique_uids = len(dm1['uid'].unique())\n",
        "\n",
        "        # 将 UID 结果存储到 DataFrame 中的 'id2' 列\n",
        "        df.at[idx, 'id2'] = unique_uids\n",
        "\n",
        "        print(f\"剧名: {title}, 不重复的UID数量: {unique_uids}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"处理剧名 {title} 时发生错误: {e}\")\n",
        "\n",
        "# 覆盖保存结果到原始 Excel 文件\n",
        "df.to_excel(file_path, index=False)\n",
        "print(f\"结果已保存到原表格 {file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Pls6liRw6fp",
        "outputId": "8a118842-86c7-4581-802d-4830e1bdbf14"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "剧名: 惊封2下, 不重复的UID数量: 9778\n",
            "剧名: 提灯看刺刀（上）, 不重复的UID数量: 5758\n",
            "剧名: 台风眼2, 不重复的UID数量: 5540\n",
            "剧名: 吞海3下, 不重复的UID数量: 4323\n",
            "剧名: 梦魇直播间1, 不重复的UID数量: 3451\n",
            "剧名: 三嫁2, 不重复的UID数量: 1986\n",
            "剧名: 跨界2, 不重复的UID数量: 1776\n",
            "剧名: 暗癖, 不重复的UID数量: 1641\n",
            "剧名: 偷风不偷月（下）, 不重复的UID数量: 1200\n",
            "剧名: 千杯, 不重复的UID数量: 829\n",
            "剧名: 于青, 不重复的UID数量: 743\n",
            "剧名: 月下安途, 不重复的UID数量: 668\n",
            "剧名: 三伏2, 不重复的UID数量: 591\n",
            "剧名: 烟花过境（BG）, 不重复的UID数量: 116\n",
            "结果已保存到原表格 /content/猫耳在播剧id（跑程序版）.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "表格版成功啦！：）"
      ],
      "metadata": {
        "id": "fdXs0mlU13GN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "试试漫播版"
      ],
      "metadata": {
        "id": "jD04KFOU5l8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# 读取上传的 Excel 文件\n",
        "file_path = '/content/漫播在更剧id（跑程序版）.xlsx'  # 修改为你的文件路径\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# 假设表格中有 '剧名' 和 '第一集链接' 两列\n",
        "titles = df['剧名']\n",
        "urls = df['第一集链接']\n",
        "\n",
        "# 为 DataFrame 添加一列 'id2'，初始为 None\n",
        "df['id2'] = None\n",
        "\n",
        "# 遍历每个剧集的名称和 '第一集链接'\n",
        "for idx, (title, url) in enumerate(zip(titles, urls)):\n",
        "    try:\n",
        "        # 直接使用链接作为 detail_id\n",
        "        new_url = url  # 直接使用链接，不再进行拼接\n",
        "\n",
        "        # 请求新的 URL，获取剧集信息\n",
        "        r = requests.get(new_url).text\n",
        "        r = str(json.loads(r)['data']['radioDramaResp']['setRespList'])\n",
        "\n",
        "        # 使用正则表达式提取集信息\n",
        "        pattern1 = re.compile(\"'vipFree': (.+?),\")\n",
        "        vipFree = re.findall(pattern1, r)\n",
        "        num = len(vipFree)\n",
        "\n",
        "        pattern2 = re.compile(\"'setId': (.+?),\")\n",
        "        setId = re.findall(pattern2, r)\n",
        "\n",
        "        # 找到所有免费集或付费集的 ID\n",
        "        episodes = [setId[i] for i in range(num) if vipFree[i] == '1']\n",
        "\n",
        "        # 如果没有免费集，查找付费集\n",
        "        if len(episodes) == 0:\n",
        "            pattern3 = re.compile(\"'payType': (.+?),\")\n",
        "            payType = re.findall(pattern3, r)\n",
        "            episodes = [setId[i] for i in range(num) if payType[i] == '1']\n",
        "\n",
        "        # 弹幕列表\n",
        "        danmu = []\n",
        "\n",
        "        # 获取每集的弹幕信息\n",
        "        for each in episodes:\n",
        "            next_url = \"https://manbo.hongrenshuo.com.cn/api/v11/radio/drama/set/danmaku/h5/pull?radioDramaSetId=%s&startTime=0&endTime=10000000\" % each\n",
        "            print(f\"获取 {title} 的弹幕信息: {next_url}\")\n",
        "            danmakuList = json.loads(requests.get(next_url).content)['b']['danmakuList']\n",
        "\n",
        "            # 提取每条弹幕的 eid\n",
        "            for j in danmakuList:\n",
        "                danmu.append(j['eid'])\n",
        "\n",
        "        # 获取不重复的 UID 数量\n",
        "        unique_uids = len(set(danmu))\n",
        "\n",
        "        # 将 UID 结果存储到 DataFrame 中的 'id2' 列\n",
        "        df.at[idx, 'id2'] = unique_uids\n",
        "\n",
        "        print(f\"剧名: {title}, 不重复的UID数量: {unique_uids}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"处理剧名 {title} 时发生错误: {e}\")\n",
        "\n",
        "# 覆盖保存结果到原始 Excel 文件\n",
        "df.to_excel(file_path, index=False)\n",
        "print(f\"结果已保存到原表格 {file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "zHzJekIu6ANv",
        "outputId": "cc006b42-2ee7-4fb6-b67d-291f42c52038"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "处理剧名 从万米高空降临 时发生错误: Expecting value: line 1 column 1 (char 0)\n",
            "处理剧名 四面佛 时发生错误: Expecting value: line 1 column 1 (char 0)\n",
            "处理剧名 臣好柔弱啊 时发生错误: Expecting value: line 1 column 1 (char 0)\n",
            "处理剧名 青梅狂想曲 时发生错误: Expecting value: line 1 column 1 (char 0)\n",
            "处理剧名 铜雀锁金钗 时发生错误: Expecting value: line 1 column 1 (char 0)\n",
            "处理剧名 一枝（第二季） 时发生错误: Expecting value: line 1 column 1 (char 0)\n",
            "处理剧名 一替成名（上） 时发生错误: Expecting value: line 1 column 1 (char 0)\n",
            "处理剧名 为了聂先生的恩宠（下） 时发生错误: Expecting value: line 1 column 1 (char 0)\n",
            "处理剧名 在校生 时发生错误: Expecting value: line 1 column 1 (char 0)\n",
            "处理剧名 溺酒 时发生错误: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-88e28fa57c68>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'radioDramaResp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'setRespList'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-88e28fa57c68>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"处理剧名 {title} 时发生错误: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# 覆盖保存结果到原始 Excel 文件\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    618\u001b[0m                 )\n\u001b[1;32m    619\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def send_multipart(\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "检查url是否正确："
      ],
      "metadata": {
        "id": "ztD-Y0c06qdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 读取上传的 Excel 文件\n",
        "file_path = '/content/漫播在更剧id（跑程序版）.xlsx'  # 修改为你的文件路径\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# 假设表格中有 '剧名' 和 '第一集链接' 两列\n",
        "titles = df['剧名']\n",
        "urls = df['第一集链接']\n",
        "\n",
        "# 遍历每个剧集的名称和 '第一集链接'\n",
        "for title, url in zip(titles, urls):\n",
        "    print(f\"剧名: {title}, URL: {url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjN45djP6tPE",
        "outputId": "2eb10b7d-54fa-4fbd-ad57-e67ed0698ad1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "剧名: 从万米高空降临, URL: https://www.kilamanbo.com/manbo/pc/detail?id=1944764730950287431&collectId=1966909818551664738\n",
            "剧名: 四面佛, URL: https://www.kilamanbo.com/manbo/pc/detail?id=1946295508834189409&collectId=1967116320579256664\n",
            "剧名: 臣好柔弱啊, URL: https://www.kilamanbo.com/manbo/pc/detail?id=1963615668829945940&collectId=1975452822036021343\n",
            "剧名: 青梅狂想曲, URL: https://www.kilamanbo.com/manbo/pc/detail?id=1955860104649637973&collectId=1984633207257038861\n",
            "剧名: 铜雀锁金钗, URL: https://www.kilamanbo.com/manbo/pc/detail?id=1983255583611945059&collectId=1986677250912682121\n",
            "剧名: 一枝（第二季）, URL: https://www.kilamanbo.com/manbo/pc/detail?id=1974326518402252851&collectId=1977313328854204479\n",
            "剧名: 一替成名（上）, URL: https://www.kilamanbo.com/manbo/pc/detail?id=1969189801940746368&collectId=1983219596080971879\n",
            "剧名: 为了聂先生的恩宠（下）, URL: https://www.kilamanbo.com/manbo/pc/detail?id=1976606682179960932&collectId=1978858795526258885\n",
            "剧名: 在校生, URL: https://www.kilamanbo.com/manbo/pc/detail?id=1945472541560668226&collectId=1955466406472450067\n",
            "剧名: 溺酒, URL: https://www.kilamanbo.com/manbo/pc/detail?id=1962548124643754167&collectId=1971478074616709352\n",
            "剧名: 我的老攻是只鬼, URL: https://www.kilamanbo.com/manbo/pc/detail?id=1952266660131897442&collectId=1974036517915459683\n",
            "剧名: 鬓边不是海棠红, URL: https://www.kilamanbo.com/manbo/pc/detail?id=1966611752116289550&collectId=1972913680320299077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "继续检查"
      ],
      "metadata": {
        "id": "dmWvNGZX7QuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# 读取上传的 Excel 文件\n",
        "file_path = '/content/漫播在更剧id（跑程序版）.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# 假设表格中有 '剧名' 和 '第一集链接' 两列\n",
        "titles = df['剧名']\n",
        "urls = df['第一集链接']\n",
        "\n",
        "# 用于存储结果\n",
        "uids = []\n",
        "\n",
        "# 遍历每个剧名和 '第一集链接'\n",
        "for title, url in zip(titles, urls):\n",
        "    try:\n",
        "        print(f\"处理剧名 {title} 中...\")\n",
        "\n",
        "        # 判断链接类型并构建 API 请求的 URL\n",
        "        if 'pc' in url:\n",
        "            detail_id = url.split('Id=')[1].split('&')[0]  # 提取 detail_id\n",
        "            new_url = f\"https://manbo.hongdoulive.com/web_manbo/dramaSetDetail?dramaSetId={detail_id}\"\n",
        "            temp = 'data'\n",
        "        else:\n",
        "            episode_id = url.split('id=')[1][:19]  # 提取 episode_id\n",
        "            radio_id = url.split('DramaId=')[1][:19]  # 提取 radio_id\n",
        "            new_url = f\"https://manbo.hongrenshuo.com.cn/api/v207/radio/drama/set/h5/detail?radioDramaSetId={episode_id}&radioDramaId={radio_id}\"\n",
        "            temp = 'b'\n",
        "\n",
        "        # 发送请求并解析返回结果\n",
        "        r = requests.get(new_url).text\n",
        "        r = str(json.loads(r)[temp]['radioDramaResp']['setRespList'])\n",
        "\n",
        "        # 正则匹配提取付费集信息\n",
        "        pattern1 = re.compile(\"'vipFree': (.+?),\")\n",
        "        vipFree = re.findall(pattern1, r)\n",
        "        num = len(vipFree)\n",
        "\n",
        "        pattern2 = re.compile(\"'setId': (.+?),\")\n",
        "        setId = re.findall(pattern2, r)\n",
        "\n",
        "        # 找到所有免费集或付费集的 ID\n",
        "        episodes = [setId[i] for i in range(num) if vipFree[i] == '1']\n",
        "\n",
        "        if len(episodes) == 0:\n",
        "            pattern3 = re.compile(\"'payType': (.+?),\")\n",
        "            payType = re.findall(pattern3, r)\n",
        "            episodes = [setId[i] for i in range(num) if payType[i] == '1']\n",
        "\n",
        "        # 弹幕列表\n",
        "        danmu = []\n",
        "\n",
        "        # 获取每集的弹幕信息\n",
        "        for each in episodes:\n",
        "            next_url = f\"https://manbo.hongrenshuo.com.cn/api/v11/radio/drama/set/danmaku/h5/pull?radioDramaSetId={each}&startTime=0&endTime=10000000\"\n",
        "            danmakuList = json.loads(requests.get(next_url).content)['b']['danmakuList']\n",
        "\n",
        "            # 提取每条弹幕的 uid\n",
        "            for j in danmakuList:\n",
        "                danmu.append(j['eid'])\n",
        "\n",
        "        # 去重并获取最终的 UID 数量\n",
        "        unique_uids = len(set(danmu))\n",
        "        print(f\"{title} 的 UID 数量: {unique_uids}\")\n",
        "\n",
        "        # 将 UID 数量存储到结果列表中\n",
        "        uids.append(unique_uids)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"处理剧名 {title} 时发生错误: {str(e)}\")\n",
        "        uids.append(None)\n",
        "\n",
        "# 将 UID 结果添加到原表格\n",
        "df['id2'] = uids\n",
        "\n",
        "# 保存表格为新的 Excel 文件\n",
        "output_path = '/content/漫播在更剧id（跑程序版）.xlsx'\n",
        "df.to_excel(output_path, index=False)\n",
        "print(f\"处理完成，结果已保存至 {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "zIUvjbQf7SkH",
        "outputId": "00d2c837-5319-4ac8-fe2d-ba8dbfe88500"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "处理剧名 从万米高空降临 中...\n",
            "从万米高空降临 的 UID 数量: 7323\n",
            "处理剧名 四面佛 中...\n",
            "四面佛 的 UID 数量: 4024\n",
            "处理剧名 臣好柔弱啊 中...\n",
            "臣好柔弱啊 的 UID 数量: 744\n",
            "处理剧名 青梅狂想曲 中...\n",
            "青梅狂想曲 的 UID 数量: 613\n",
            "处理剧名 铜雀锁金钗 中...\n",
            "铜雀锁金钗 的 UID 数量: 760\n",
            "处理剧名 一枝（第二季） 中...\n",
            "一枝（第二季） 的 UID 数量: 449\n",
            "处理剧名 一替成名（上） 中...\n",
            "一替成名（上） 的 UID 数量: 418\n",
            "处理剧名 为了聂先生的恩宠（下） 中...\n",
            "为了聂先生的恩宠（下） 的 UID 数量: 18\n",
            "处理剧名 在校生 中...\n",
            "在校生 的 UID 数量: 2509\n",
            "处理剧名 溺酒 中...\n",
            "溺酒 的 UID 数量: 2309\n",
            "处理剧名 我的老攻是只鬼 中...\n",
            "我的老攻是只鬼 的 UID 数量: 1165\n",
            "处理剧名 鬓边不是海棠红 中...\n",
            "鬓边不是海棠红 的 UID 数量: 726\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Cannot save file into a non-existent directory: '/mnt/data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f77aa4f9c8a1>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# 保存表格为新的 Excel 文件\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/mnt/data/更新后的猫耳在播剧id.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"处理完成，结果已保存至 {output_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   2343\u001b[0m             \u001b[0minf_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minf_rep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         )\n\u001b[0;32m-> 2345\u001b[0;31m         formatter.write(\n\u001b[0m\u001b[1;32m   2346\u001b[0m             \u001b[0mexcel_writer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m             \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/excel.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0;31m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;31m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m             writer = ExcelWriter(  # type: ignore[abstract]\n\u001b[0m\u001b[1;32m    947\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m                 \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mengine_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         )\n\u001b[1;32m   1262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelWriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             self._handles = get_handle(\n\u001b[0m\u001b[1;32m   1264\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/mnt/data'"
          ]
        }
      ]
    }
  ]
}